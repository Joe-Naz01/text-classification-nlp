{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utyvfe2uApr9",
        "outputId": "c50b5dcb-32c3-49bf-ed3b-8ae9c2f80683"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lNT3Nk6V4RsD"
      },
      "outputs": [],
      "source": [
        "import re, random, numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map a unique index to each word\n",
        "words = [\"This\", \"book\", \"was\", \"fantastic\", \"I\", \"really\", \"love\", \"science\", \"fiction\", \"but\", \"the\", \"protagonist\", \"was\", \"rude\", \"sometimes\"]\n",
        "word_to_idx = {word: i for i, word in enumerate(words)}\n",
        "\n",
        "# Convert word_to_idx to a tensor\n",
        "inputs = torch.LongTensor([word_to_idx[w] for w in words])\n",
        "\n",
        "# Initialize embedding layer with ten dimensions\n",
        "embedding = nn.Embedding(num_embeddings=len(words), embedding_dim=10)\n",
        "\n",
        "# Pass the tensor to the embedding layer\n",
        "output = embedding(inputs)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uonmwzc_6cWp",
        "outputId": "baba833f-2d9b-49d1-cc64-fc74d90a8427"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-6.0225e-02, -7.2780e-01, -2.9647e-01,  4.8080e-01, -1.6944e+00,\n",
            "          2.8657e+00,  5.2318e-01,  1.2359e-01, -1.0793e+00, -6.6700e-02],\n",
            "        [-5.9041e-01, -1.3458e+00,  8.0741e-01,  4.4897e-01,  1.5597e-01,\n",
            "          4.5849e-01, -3.9183e-02, -1.7998e+00,  9.0804e-01, -6.3406e-02],\n",
            "        [ 1.0874e+00,  6.6480e-01,  6.0049e-02,  2.3289e-01,  4.2793e-02,\n",
            "          4.8082e-01, -1.0698e+00, -8.2554e-01, -2.7300e-01,  1.1013e+00],\n",
            "        [-9.8179e-01, -3.9346e-01,  9.5218e-03,  1.9166e+00, -5.2530e-01,\n",
            "          9.7612e-01,  1.1070e+00, -3.8642e-01,  2.4127e+00, -1.9479e-01],\n",
            "        [-1.1190e+00, -7.7903e-01, -5.5399e-01, -1.5482e+00, -3.2684e-01,\n",
            "          9.7186e-01, -1.0295e-01,  6.3112e-01,  7.8727e-01, -4.3701e-01],\n",
            "        [-3.0742e-01, -6.1216e-01,  1.5429e+00, -1.5945e+00,  1.0175e+00,\n",
            "          6.5022e-01, -1.6212e-01, -6.5605e-01,  1.4241e-01,  1.5387e+00],\n",
            "        [-9.8331e-01,  1.4893e+00,  1.4111e-01,  4.9128e-01, -9.8597e-02,\n",
            "         -2.2160e+00, -1.1209e+00,  1.5208e+00, -5.5175e-01, -2.1928e+00],\n",
            "        [ 3.2432e-01, -5.2377e-01,  4.5557e-01,  3.6436e-01, -1.4027e+00,\n",
            "          6.4878e-01, -5.5231e-01, -9.9868e-01,  8.5881e-01, -1.4676e+00],\n",
            "        [-2.0863e+00, -5.6582e-02, -3.4555e-01,  1.4435e+00,  1.1409e+00,\n",
            "          1.2260e+00, -1.2191e+00, -5.2337e-01,  2.7500e-01,  3.5410e-01],\n",
            "        [ 3.0137e-01,  1.5149e+00, -1.1026e+00, -6.0215e-01,  1.5041e-01,\n",
            "         -2.0674e-01,  1.7303e-01,  5.3285e-01, -5.1563e-01, -1.2468e-03],\n",
            "        [ 1.4090e-02, -1.5181e+00, -1.1089e+00, -3.2949e-01, -2.8687e-01,\n",
            "          5.9525e-01,  2.1764e+00, -3.9504e-01,  1.8677e-02, -9.2601e-01],\n",
            "        [-5.9199e-01,  1.7174e-01,  5.2752e-01, -2.6169e-01,  1.0928e+00,\n",
            "          1.8831e+00, -1.6513e-01,  1.1827e+00, -7.4576e-01,  1.1028e+00],\n",
            "        [ 1.0874e+00,  6.6480e-01,  6.0049e-02,  2.3289e-01,  4.2793e-02,\n",
            "          4.8082e-01, -1.0698e+00, -8.2554e-01, -2.7300e-01,  1.1013e+00],\n",
            "        [-1.3775e-01,  1.5583e-01, -5.1157e-01, -4.0416e-01,  3.8821e-01,\n",
            "         -3.0505e+00,  4.8828e-02, -5.1346e-01, -3.1603e-01, -6.5323e-01],\n",
            "        [-1.2160e-01,  1.5655e-01,  5.6773e-01,  8.0180e-01, -4.6397e-01,\n",
            "          6.7225e-01,  1.6712e+00,  1.9809e-01,  1.3421e+00, -7.0267e-03]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT CLASSIFICATION USING CNN"
      ],
      "metadata": {
        "id": "J3c5Qft3-QvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class TextClassificationCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super(TextClassificationCNN, self).__init__()\n",
        "        # Initialize the embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.conv = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc = nn.Linear(embed_dim, 2)\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text).permute(0, 2, 1)\n",
        "        # Pass the embedded text through the convolutional layer and apply a ReLU\n",
        "        conved = F.relu(self.conv(embedded))\n",
        "        conved = conved.mean(dim=2)\n",
        "        return self.fc(conved)"
      ],
      "metadata": {
        "id": "iZrg5yw61KoP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [\"i\", \"love\", \"this\", \"book\", \"do\", \"not\", \"like\"]\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "vocab_size = len(word_to_idx)\n",
        "embed_dim = 10\n",
        "book_samples = [    (\"The story was captivating and kept me hooked until the end.\".split(),1),    (\"I found the characters shallow and the plot predictable.\".split(),0)]\n",
        "model = TextClassificationCNN(vocab_size, embed_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "Me5icv4q2Mhu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(10):\n",
        "    # Iterate over book_samples instead of data\n",
        "    for sentence, label in book_samples:\n",
        "        # Clear the gradients\n",
        "        model.zero_grad()\n",
        "        # Use word_to_idx instead of word_to_ix\n",
        "        sentence = torch.LongTensor([word_to_idx.get(w, 0) for w in sentence]).unsqueeze(0)\n",
        "        label = torch.LongTensor([int(label)])\n",
        "        outputs = model(sentence)\n",
        "        loss = criterion(outputs, label)\n",
        "        loss.backward()\n",
        "        # Update the parameters\n",
        "        optimizer.step()\n",
        "print('Training complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3mAOsXv2nmu",
        "outputId": "565645c5-ce78-4c6c-f55d-5b6b23285e66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will be a great addition to the PyBooks' recommendation engine, assisting the team in understanding users' sentiments towards different books."
      ],
      "metadata": {
        "id": "v7kOK9TAAg3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_reviews = [\n",
        "    \"I love this book\".split(),\n",
        "    \"I do not like this book\".split()\n",
        "]\n",
        "for review in book_reviews:\n",
        "    # Convert the review words into tensor form, converting to lowercase and handling unknown words\n",
        "    input_tensor = torch.tensor([word_to_idx.get(w.lower(), 0) for w in review], dtype =torch.long).unsqueeze(0)\n",
        "    # Get the model's output\n",
        "    outputs = model(input_tensor)\n",
        "    # Find the index of the most likely sentiment category\n",
        "    _, predicted_label = torch.max(outputs.data, 1)\n",
        "    # Convert the predicted label into a sentiment string\n",
        "    sentiment = \"Positive\" if predicted_label.item() == 1 else \"Negative\"\n",
        "    print(f\"Book Review: {' '.join(review)}\")\n",
        "    print(f\"Sentiment: {sentiment}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1NGB68P21hn",
        "outputId": "fa75fd55-e7d6-4ad3-c65c-d5afa48d3503"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Book Review: I love this book\n",
            "Sentiment: Positive\n",
            "\n",
            "Book Review: I do not like this book\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT CLASSIFICATION USING RNN"
      ],
      "metadata": {
        "id": "pu4To8uVFHA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Load the dataset\n",
        "categories = ['rec.autos', 'sci.med', 'comp.graphics']\n",
        "X_train_seq = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)\n",
        "X_test_seq = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state =42)\n",
        "\n",
        "def preprocess_text(documents):\n",
        "    preprocessed_docs = []\n",
        "    for doc in documents:\n",
        "        # Convert to lowercase\n",
        "        doc = doc.lower()\n",
        "        # Remove punctuation and special characters\n",
        "        doc = re.sub(r'[^a-zA-Z\\s]', '', doc)\n",
        "        # Tokenize\n",
        "        tokens = doc.split()\n",
        "        preprocessed_docs.append(tokens)\n",
        "    return preprocessed_docs\n",
        "\n",
        "# Apply the preprocessing function to the training and testing data\n",
        "X_train_tokens = preprocess_text(X_train_seq.data)\n",
        "X_test_tokens = preprocess_text(X_test_seq.data)\n",
        "\n",
        "# Create vocabulary and word_to_index mapping from training data\n",
        "all_train_tokens = [token for doc in X_train_tokens for token in doc]\n",
        "word_counts = Counter(all_train_tokens)\n",
        "vocab = [word for word, count in word_counts.most_common()]\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Convert tokens to numerical sequences\n",
        "X_train_numerical = [[word_to_index.get(word, 0) for word in doc] for doc in X_train_tokens]\n",
        "X_test_numerical = [[word_to_index.get(word, 0) for word in doc] for doc in X_test_tokens]\n",
        "\n",
        "# Recalculate max_len based on both training and testing sets\n",
        "max_len = max(max(len(doc) for doc in X_train_numerical), max(len(doc) for doc in X_test_numerical))\n",
        "\n",
        "X_train_padded = np.zeros((len(X_train_numerical), max_len), dtype=int)\n",
        "for i, doc in enumerate(X_train_numerical):\n",
        "    X_train_padded[i, :len(doc)] = doc\n",
        "\n",
        "X_test_padded = np.zeros((len(X_test_numerical), max_len), dtype=int)\n",
        "for i, doc in enumerate(X_test_numerical):\n",
        "    X_test_padded[i, :len(doc)] = doc\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.LongTensor(X_train_padded)\n",
        "X_test_tensor = torch.LongTensor(X_test_padded)\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "y_train_tensor = torch.LongTensor(X_train_seq.target)\n",
        "y_test_tensor = torch.LongTensor(X_test_seq.target)\n",
        "\n",
        "# Create PyTorch TensorDataset for training and testing data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create PyTorch DataLoader for training and testing datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "input_size = len(word_to_index) # Use the actual vocabulary size\n",
        "embed_dim = 32 # Define embedding dimension\n",
        "hidden_size = 32\n",
        "num_layers = 2\n",
        "num_classes = 3\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers, num_classes):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim) # Add embedding layer\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_size, num_layers, batch_first=True) # Change input size to embed_dim\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x) # Pass through embedding layer\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) # Initialize h0 with correct batch size\n",
        "        out, _ = self.rnn(embedded, h0) # Pass embedded input to RNN\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Initialize the model with vocabulary size and embedding dimension\n",
        "rnn_model = RNNModel(input_size, embed_dim, hidden_size, num_layers, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "_4Yxi2tKVm8h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da7af243",
        "outputId": "4630ea8b-e9bf-416e-8ca0-6aed7712f2ca"
      },
      "source": [
        "# Set the model to training mode\n",
        "rnn_model.train()\n",
        "\n",
        "# Train the model for a few epochs\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = rnn_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n",
        "print('Training complete!')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.1190\n",
            "Epoch [2/5], Loss: 1.1066\n",
            "Epoch [3/5], Loss: 1.1030\n",
            "Epoch [4/5], Loss: 1.1019\n",
            "Epoch [5/5], Loss: 1.1099\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT CLASSIFICATION USING LSTM"
      ],
      "metadata": {
        "id": "4ub10L0GHmjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LSTM and the output layer with parameters\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        # Add embedding layer\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size) # Using hidden_size as embed_dim\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True) # Change input size to hidden_size (embed_dim)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through embedding layer\n",
        "        embedded = self.embedding(x)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        # Pass embedded input to LSTM\n",
        "        out, _ = self.lstm(embedded, (h0, c0))\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Initialize model with required parameters\n",
        "# Use the vocabulary size for input_size\n",
        "lstm_model = LSTMModel(len(word_to_index), hidden_size, num_layers, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "DEsXSGi_Wa-4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to training mode\n",
        "lstm_model.train()\n",
        "\n",
        "# Train the model by iterating through the DataLoader\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = lstm_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n",
        "print('Training complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g68rsieHlxB",
        "outputId": "2ff72b3e-1594-4665-b545-a41db22aae4a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.1034\n",
            "Epoch [2/5], Loss: 1.0999\n",
            "Epoch [3/5], Loss: 1.1001\n",
            "Epoch [4/5], Loss: 1.0996\n",
            "Epoch [5/5], Loss: 1.0992\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT CLASSIFICATION USING GRU"
      ],
      "metadata": {
        "id": "lK4W4M3mHzVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the GRU model\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size) # Add embedding layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers,  batch_first=True) # Change input size to hidden_size (embed_dim)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x) # Pass through embedding layer\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        out, _ = self.gru(embedded, h0) # Pass embedded input to GRU\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Initialize the model\n",
        "gru_model = GRUModel(input_size, hidden_size, num_layers, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "OTJc9j8RX_4p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train the model and backpropagate the loss after initialization\n",
        "# Set the model to training mode\n",
        "gru_model.train()\n",
        "\n",
        "# Train the model for a few epochs\n",
        "num_epochs = 5 # Using 5 epochs for consistency with previous models\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = gru_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n",
        "print('Training complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpp8FGJnH2aX",
        "outputId": "f05b3ae2-0970-4a34-c935-e650f60dd8ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.1117\n",
            "Epoch [2/5], Loss: 1.1030\n",
            "Epoch [3/5], Loss: 1.1019\n",
            "Epoch [4/5], Loss: 1.1010\n",
            "Epoch [5/5], Loss: 1.1005\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION METRICS"
      ],
      "metadata": {
        "id": "JcgMTt4LT1Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score\n",
        "\n",
        "# Put model in eval mode\n",
        "rnn_model.eval()\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    outputs = rnn_model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Create metric instances\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=3)\n",
        "precision = Precision(task=\"multiclass\", num_classes=3)\n",
        "recall = Recall(task=\"multiclass\", num_classes=3)\n",
        "f1 = F1Score(task=\"multiclass\", num_classes=3)\n",
        "\n",
        "# Ensure everything is on same device\n",
        "predicted = predicted.cpu()\n",
        "y_test_tensor = y_test_tensor.cpu()\n",
        "\n",
        "# Compute metrics (correct argument order)\n",
        "accuracy_score = accuracy(y_test_tensor, predicted)\n",
        "precision_score = precision(y_test_tensor, predicted)\n",
        "recall_score = recall(y_test_tensor, predicted)\n",
        "f1_score = f1(y_test_tensor, predicted)\n",
        "\n",
        "print(f\"RNN Model - Accuracy: {accuracy_score:.4f}, Precision: {precision_score:.4f}, Recall: {recall_score:.4f}, F1 Score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ1F40I5T0KV",
        "outputId": "d573b5db-58ae-4a9b-ea6d-f0003b51fc2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN Model - Accuracy: 0.3362, Precision: 0.3362, Recall: 0.3362, F1 Score: 0.3362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the metrics\n",
        "accuracy = Accuracy(task='multiclass', num_classes=3)\n",
        "precision = Precision(task='multiclass', num_classes=3)\n",
        "recall = Recall(task='multiclass', num_classes=3)\n",
        "f1 = F1Score(task='multiclass', num_classes=3)\n",
        "\n",
        "# Put models in eval mode\n",
        "lstm_model.eval()\n",
        "gru_model.eval()\n",
        "\n",
        "# Generate predictions for LSTM model\n",
        "with torch.no_grad():\n",
        "    outputs_lstm = lstm_model(X_test_tensor)\n",
        "    _, y_pred_lstm = torch.max(outputs_lstm, 1)\n",
        "\n",
        "# Generate predictions for GRU model\n",
        "with torch.no_grad():\n",
        "    outputs_gru = gru_model(X_test_tensor)\n",
        "    _, y_pred_gru = torch.max(outputs_gru, 1)\n",
        "\n",
        "# Ensure everything is on same device\n",
        "y_pred_lstm = y_pred_lstm.cpu()\n",
        "y_pred_gru = y_pred_gru.cpu()\n",
        "y_test_tensor = y_test_tensor.cpu() # Use y_test_tensor\n",
        "\n",
        "# Calculate metrics for the LSTM model\n",
        "accuracy_1 = accuracy(y_pred_lstm, y_test_tensor)\n",
        "precision_1 = precision(y_pred_lstm, y_test_tensor)\n",
        "recall_1 = recall(y_pred_lstm, y_test_tensor)\n",
        "f1_1 = f1(y_pred_lstm, y_test_tensor)\n",
        "print(\"LSTM Model - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(accuracy_1, precision_1, recall_1, f1_1))\n",
        "\n",
        "# Calculate metrics for the GRU model\n",
        "accuracy_2 = accuracy(y_pred_gru, y_test_tensor)\n",
        "precision_2 = precision(y_pred_gru, y_test_tensor)\n",
        "recall_2 = recall(y_pred_gru, y_test_tensor)\n",
        "f1_2 = f1(y_pred_gru, y_test_tensor)\n",
        "print(\"GRU Model - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(accuracy_2, precision_2, recall_2, f1_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH8Malb1XsV4",
        "outputId": "98fc63c7-8b10-4092-bef9-1991ec383f22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Model - Accuracy: 0.3294, Precision: 0.3294, Recall: 0.3294, F1 Score: 0.3294\n",
            "GRU Model - Accuracy: 0.3353, Precision: 0.3353, Recall: 0.3353, F1 Score: 0.3353\n"
          ]
        }
      ]
    }
  ]
}